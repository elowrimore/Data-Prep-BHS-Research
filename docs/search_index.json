[["index.html", "Data Preperation for Bighorn Sheep Research Project Chapter 1 Background 1.1 Purpose of This Book 1.2 Ecological Background of Study 1.3 Study System", " Data Preperation for Bighorn Sheep Research Project Emily Lowrimore 2024-12-13 Chapter 1 Background 1.1 Purpose of This Book The purpose of this document is to create a detailed and transparent record of data preparation steps undertaken for my research project on the Lower John Day bighorn sheep population. By documenting the processes of database creation, cleaning, and exploration, this document ensures that all data manipulation and organization steps are clearly recorded, enabling reproducibility and facilitating collaboration. Clean and tidy data are foundational to robust analyses, as they minimize errors and streamline subsequent modeling and interpretation. Recording every stage of data manipulation not only improves transparency but also allows for the verification and replication of findings, which are cornerstones of science integrity. Additionally, by following a reproducible workflow, this document aims to act as a simple guide for preparing ecological data for analysis and provide example code with detailed explanation and commenting. 1.2 Ecological Background of Study Demographic variation in large herbivores is shaped by an interplay of intrinsic and extrinsic factors, with adult female and juvenile survival serving as key determinants of population stability. Nutrition is a fundamental driver of these dynamics, as the quality and availability of forage across the landscape directly influence individual fitness and reproductive success. Foraging decisions often involve balancing nutrient acquisition with risks such as predation, competition, and human disturbance, which vary across environmental conditions and life-history stages. Social structures, particularly fission-fusion, further mediate these trade-offs by enabling flexible group sizes and compositions. Larger groups may reduce predation risk and enhance foraging efficiency, while smaller groups may limit competition or reduce disease transmission. Together, these factors interact to govern population performance, highlighting the importance of understanding these mechanisms underlying demographic outcomes. Conceptual diagram showing how nutrition and social dynamics can influence survival, which in turn, shapes population dynamics. Bighorn sheep (Ovis canadensis) are a large herbivore species where both nutrition and social dynamics play a large role in shaping population performance. However, bighorn sheep in North America have faced significant population declines due to a mix of factors including over hunting, habitat loss, and disease, particularly pneumonia. In Oregon, bighorn sheep were extirpated by 1915 and in response the Oregon Department of Fish and Wildlife began reintroducing by 1954. These reintroduction efforts have led to the establishment of several bighorn sheep herds throughout the Oregon, with varying levels of success. Picture of bighorn ewes with lambs. Picture taken by Teri Franzen. 1.3 Study System The Lower John Day River Canyon in north-central Oregon is home to a thriving population of bighorn sheep with over 1,000 individuals. The diversity of the habitat, with its mosaic of high-quality forage patches and secure escape terrain, provides an ideal setting to investigate how bighorn sheep balance nutritional needs with predation risk. Unlike many bighorn sheep populations, the Lower John Day herd has not been heavily impacted by disease, which allows for a more focused examination of the effects of nutrition and social dynamics on vital rates without the confounding influence of disease. The John Day River Canyon My research aims to examine how ewes’ use of the foodscape and group dynamics, particularly fission-fusion behavior, influence lamb survival and adult ewe survival. Studying this population will not only provide insights into the ecological mechanisms underpinning bighorn sheep demographics but will also inform management practices aimed at sustaining healthy herds across their range. To address the objectives of this study, numerous data was collected. This book will show the process of entering and organizing these data using a relational database, cleaning these data to make it tidy, and exploring these data. These steps will ensure data collected for this research project are prepared and ready to be analyzed to answer hypotheses surrounding bighorn sheep survival and habitat selection. "],["building-a-database.html", "Chapter 2 Building a Database 2.1 Organizing Data with Relational Databases 2.2 Database Design 2.3 Creating a Database 2.4 Populating a Database", " Chapter 2 Building a Database 2.1 Organizing Data with Relational Databases Organizing data is crucial for effective data management and analysis, and a relational database provides a robust framework for this purpose. By structuring data into interconnected tables that reflect real-world relationships between data entities, relational databases enhance both the integrity and consistency of the dataset. This approach encourages critical thinking about data structure while reducing redundancy and improving quality control. Additionally, the centralized storage and design of relational databases streamline data processing and facilitate efficient access, making them especially valuable for collaborative research efforts. I will be designing, building, and populating a relational database to store data collected for my research. 2.2 Database Design Building on these principles, the design of my relational database reflects the structure and scope of the data collected for my research. Each table is organized around a specific sampling unit that represents a unique level of data collection, ensuring clarity and consistency. For instance, individual sheep serve as the sampling unit for a table containing characteristics like sex, age, and body condition, while group observations use a group ID as their sampling unit to record variables such as group number, size, habitat type, and location. Each table includes a primary key, a unique identifier for every record in the table, such as an individual ID for sheep or a group ID for observations. Foreign keys, which are variables shared between tables, link these datasets and maintain relational integrity; for example, an individual ID links observations of collared ewes to their lambs or mortality records. See conceptual diagram of relational database for all data tables below. Relational database design. Primary keys (PK) are in bold and italicized, foreign keys (FK) are italicized. Defining clear sampling units ensures each table is logically structured and avoids redundancy, while primary and foreign keys enable seamless connections between related data. This relational architecture mirrors real-world relationships and facilitates accurate querying and analysis. 2.3 Creating a Database To construct the relational database for this project, I used the RSQLite and DBI packages in R, which provide an interface for creating and managing SQLite databases. This approach allows for seamless integration with R workflows, enabling efficient storage, querying, and manipulation of data directly within the R environment. 2.3.1 Install and Load Required Packages Load necessary packages using the library() function. library(RSQLite) library(DBI) Note that if these packages have never been installed on your computer use install.packages() instead. install.packages(&quot;RSQLite&quot;) install.packages(&quot;DBI&quot;) 2.3.2 Link Database The dbConnect function is used to establish a connection to a database by providing a file path. If the database file already exists at that path, it connects to it; if not, it creates a new database at the specified location. #Link database jd_sheep_db &lt;- dbConnect(RSQLite::SQLite(), &quot;C:/Users/emily/Documents/Project/Data/raw/Database/jd_sheep.db&quot;) 2.4 Populating a Database 2.4.1 Sheep Table The sheep table has the primary key of sheepID and contains data for each collared sheep including sex, age at capture, body condition, max fat, condition scorer, max body temperature, pregnancy status, whether biological samples (fecal, DNA, nasal swabs, and blood) were collected during capture, latitude and longitude of capture location, and the capture zone from which the sheep came. First, I need to create an empty table with a primary key specified, as well as foreign keys if they exists. I also imposed constraints for the data to follow to avoid data entry errors and ensure uniform labeling. dbExecute(jd_sheep_db, &quot;CREATE TABLE sheep ( sheep_id varchar(15) NOT NULL PRIMARY KEY, sex char(1) CHECK (sex IN (&#39;M&#39;, &#39;F&#39;)), age varchar(2), condition real, fat real, scorer char(2), pregnant varchar(6) CHECK (pregnant IN (&#39;Y&#39;, &#39;N&#39;, &#39;unkwn&#39;, &#39;&#39;)), lat real, long real, capture_zone varchar(15), fecal char(1) CHECK (fecal IN (&#39;Y&#39;, &#39;N&#39;)), dna char(1) CHECK (dna IN (&#39;Y&#39;, &#39;N&#39;)), nasal char(1) CHECK (nasal IN (&#39;Y&#39;, &#39;N&#39;)), blood char(1) CHECK (blood IN (&#39;Y&#39;, &#39;N&#39;)), temp real, accession char(4), notes varchar );&quot;) Next step is to populate the tables with existing csv files. First, read in the csv file. sheep &lt;- read.csv(&quot;../../../Project/Data/raw/Database/sheep.csv&quot;) As mentioned above, certain constraints will need to be enforced for the table to be populated properly. I double checked these constraints by using names() to get the column names or head() to look at the first few rows of data. names(sheep) ## [1] &quot;sheep_id&quot; &quot;sex&quot; &quot;age&quot; &quot;condition&quot; &quot;fat&quot; ## [6] &quot;scorer&quot; &quot;pregnant&quot; &quot;lat&quot; &quot;long&quot; &quot;capture_zone&quot; ## [11] &quot;fecal&quot; &quot;dna&quot; &quot;nasal&quot; &quot;blood&quot; &quot;temp&quot; ## [16] &quot;accession&quot; &quot;notes&quot; head(sheep, 3) ## sheep_id sex age condition fat scorer pregnant lat long ## 1 purple03 F 4+ 1.5 0 RL Y 45.25299 -120.5251 ## 2 white48 F 4+ 2.0 0 RL Y 45.32121 -120.5393 ## 3 orange74 F 4 2.0 1 RL Y 45.29759 -120.5340 ## capture_zone fecal dna nasal blood temp accession ## 1 AdobePoint Y Y Y Y 103.1 9381 ## 2 WilsonPoint Y Y Y Y 103.7 9362 ## 3 WilsonPoint Y Y Y Y 104.5 9389 ## notes ## 1 Broken tail (old injury). Possible blind in right eye. ## 2 Eyes looked a little buggy, but seemed fine otherwise. ## 3 Only 1 tiger top of blood. Everything looks good, now I populate the table. Use dbExecute()to do this. dbWriteTable(jd_sheep_db, &quot;sheep&quot;, sheep, append = TRUE) Now, I confirm that the data was loaded properly. dbGetQuery(jd_sheep_db, &quot;SELECT * FROM sheep LIMIT 3&quot;) ## sheep_id sex age condition fat scorer pregnant lat long ## 1 purple03 F 4+ 1.5 0 RL Y 45.25299 -120.5251 ## 2 white48 F 4+ 2.0 0 RL Y 45.32121 -120.5393 ## 3 orange74 F 4 2.0 1 RL Y 45.29759 -120.5340 ## capture_zone fecal dna nasal blood temp accession ## 1 AdobePoint Y Y Y Y 103.1 9381 ## 2 WilsonPoint Y Y Y Y 103.7 9362 ## 3 WilsonPoint Y Y Y Y 104.5 9389 ## notes ## 1 Broken tail (old injury). Possible blind in right eye. ## 2 Eyes looked a little buggy, but seemed fine otherwise. ## 3 Only 1 tiger top of blood. Repeat these steps for each table in the database. 2.4.2 Observations Table The observations table has the primary key of groupID and contains data collected during sheep observations including characteristics of the observation site such as date, number of observers and primary observer, coordinates of group of sheep, habitat type, slope, aspect, weather, temperation, and gernal location. The total number of sheep within the group is recorded as well as the composition of ewes, lambs, yearling ewes, yearling rams, and rams in the group. dbExecute(jd_sheep_db, &quot;CREATE TABLE observations ( group_id char(7) NOT NULL PRIMARY KEY, date date, n_observers integer, lead_observer varchar(3), lat real, long real, habitat varchar(10) CHECK (habitat IN (&#39;grass&#39;, &#39;cliff&#39;, &#39;outcrop&#39;, &#39;scree&#39;, &#39;mixed&#39;)), slope varchar(10) CHECK (slope IN (&#39;top&#39;, &#39;mid&#39;, &#39;bottom&#39;)), aspect varchar(2) CHECK (aspect IN (&#39;N&#39;, &#39;NW&#39;, &#39;NE&#39;, &#39;S&#39;, &#39;SW&#39;, &#39;SE&#39;, &#39;E&#39;, &#39;W&#39;)), weather varchar(20) CHECK (weather IN (&#39;sunny&#39;, &#39;cloudy&#39;, &#39;overcast&#39;, &#39;rainy&#39;, &#39;windy_sunny&#39;, &#39;windy_cloudy&#39;, &#39;windy_overcast&#39;, &#39;windy_rainy&#39;)), temp integer, location varchar(25), total integer, ewes integer, lambs integer, year_ewes integer, year_rams integer, rams integer, notes varchar );&quot;) Read in the csv file. observations &lt;- read.csv(&quot;../../../Project/Data/raw/Database/observations.csv&quot;) Double check csv matches empty table. names(observations) ## [1] &quot;group_id&quot; &quot;date&quot; &quot;n_observers&quot; &quot;lead_observer&quot; ## [5] &quot;lat&quot; &quot;long&quot; &quot;habitat&quot; &quot;slope&quot; ## [9] &quot;aspect&quot; &quot;weather&quot; &quot;temp&quot; &quot;location&quot; ## [13] &quot;total&quot; &quot;ewes&quot; &quot;lambs&quot; &quot;year_ewes&quot; ## [17] &quot;year_rams&quot; &quot;rams&quot; &quot;notes&quot; head(observations, 3) ## group_id date n_observers lead_observer lat long habitat slope ## 1 240520D 5/20/2024 NA NA 45.21563 -120.5502 outcrop mid ## 2 240521B 5/21/2024 NA NA 45.41892 -120.5050 outcrop mid ## 3 240522B 5/22/2024 NA NA 45.47276 -120.4737 outcrop mid ## aspect weather temp location total ewes lambs year_ewes year_rams rams ## 1 NE cloudy 62 horseshoe bend 2 2 0 0 0 0 ## 2 SE cloudy 52 devil&#39;s canyon 6 3 3 0 0 0 ## 3 N cloudy NA hardstone 50 28 19 3 0 0 ## notes ## 1 NA ## 2 NA ## 3 NA Populate the table. dbWriteTable(jd_sheep_db, &quot;observations&quot;, observations, append = TRUE) Confirm that the data was loaded properly. dbGetQuery(jd_sheep_db, &quot;SELECT * FROM observations LIMIT 3&quot;) ## group_id date n_observers lead_observer lat long habitat slope ## 1 240520D 5/20/2024 NA &lt;NA&gt; 45.21563 -120.5502 outcrop mid ## 2 240521B 5/21/2024 NA &lt;NA&gt; 45.41892 -120.5050 outcrop mid ## 3 240522B 5/22/2024 NA &lt;NA&gt; 45.47276 -120.4737 outcrop mid ## aspect weather temp location total ewes lambs year_ewes year_rams rams ## 1 NE cloudy 62 horseshoe bend 2 2 0 0 0 0 ## 2 SE cloudy 52 devil&#39;s canyon 6 3 3 0 0 0 ## 3 N cloudy NA hardstone 50 28 19 3 0 0 ## notes ## 1 &lt;NA&gt; ## 2 &lt;NA&gt; ## 3 &lt;NA&gt; 2.4.3 Mortalities Table This contains information if a sheep has died using sheepID as both the primary key and the foregin key linking it back to the Sheep Table. Data in this table includes the age of the sheep at time of death, when we received an alert of mortality signal from the collar, when we investigated the mortality and retreived the collar, and the hypothesized cause of death. dbExecute(jd_sheep_db, &quot;CREATE TABLE mortalities ( sheep_id varchar(15) NOT NULL PRIMARY KEY, age varchar(2), signal date, retrieved date, cause varchar(9) CHECK (cause IN (&#39;cougar&#39;, &#39;predation&#39;, &#39;unknwn&#39;, &#39;harvest&#39;, &#39;capture&#39;)), notes varchar, FOREIGN KEY (sheep_id) REFERENCES sheep(sheep_id) );&quot;) Read in the csv file. mortalities &lt;- read.csv(&quot;../../../Project/Data/raw/Database/mortalities.csv&quot;) Double check csv matches empty table. names(mortalities) ## [1] &quot;sheep_id&quot; &quot;age&quot; &quot;signal&quot; &quot;retrieved&quot; &quot;cause&quot; &quot;notes&quot; head(mortalities, 3) ## sheep_id age signal retrieved cause ## 1 purple25 5 9/26/2024 9/30/2024 unknwn ## 2 purple03 4+ 7/9/2024 7/11/2024 cougar ## 3 orange64 4+ capture ## notes ## 1 ## 2 ## 3 broken leg during capture, euthenized Populate the table. dbWriteTable(jd_sheep_db, &quot;mortalities&quot;, mortalities, append = TRUE) Confirm that the data was loaded properly. dbGetQuery(jd_sheep_db, &quot;SELECT * FROM mortalities LIMIT 3&quot;) ## sheep_id age signal retrieved cause ## 1 purple25 5 9/26/2024 9/30/2024 unknwn ## 2 purple03 4+ 7/9/2024 7/11/2024 cougar ## 3 orange64 4+ capture ## notes ## 1 ## 2 ## 3 broken leg during capture, euthenized 2.4.4 Lambs Table This table uses the name of each lamb as a primary key and includes infomation on the lamb including the birthdate, date first observed, date last observed, and whether the lamb survived or not. The lambs mother (sheepID) serves as the foreign key linking it back to the Sheep Table. dbExecute(jd_sheep_db, &quot;CREATE TABLE lambs ( name varchar(15) NOT NULL PRIMARY KEY, sheep_id varchar(15), birthdate date, first_seen date, fate varchar(10) CHECK (fate IN (&#39;weaned&#39;, &#39;deceased&#39;, &#39;unknwn&#39;)), last_seen date, notes varchar, FOREIGN KEY (sheep_id) REFERENCES sheep(sheep_id) );&quot;) Read in the csv file. lambs &lt;- read.csv(&quot;../../../Project/Data/raw/Database/lambs.csv&quot;) Double check csv matches empty table. names(lambs) ## [1] &quot;name&quot; &quot;birthdate&quot; &quot;first_seen&quot; &quot;fate&quot; &quot;last_seen&quot; ## [6] &quot;sheep_id&quot; &quot;notes&quot; head(lambs, 3) ## name birthdate first_seen fate last_seen sheep_id ## 1 adam 4/14/2024 4/15/2024 weaned orange56 ## 2 bailey 4/16/2024 4/16/2024 deceased 5/18/2024 white36 ## 3 baker 4/18/2024 4/19/2024 weaned orange60 ## notes ## 1 ## 2 observed with a broken leg for ~3 weeks prior to mortality ## 3 Populate the table. dbWriteTable(jd_sheep_db, &quot;lambs&quot;, lambs, append = TRUE) Confirm that the data was loaded properly. dbGetQuery(jd_sheep_db, &quot;SELECT * FROM lambs LIMIT 3&quot;) ## name sheep_id birthdate first_seen fate last_seen ## 1 adam orange56 4/14/2024 4/15/2024 weaned ## 2 bailey white36 4/16/2024 4/16/2024 deceased 5/18/2024 ## 3 baker orange60 4/18/2024 4/19/2024 weaned ## notes ## 1 ## 2 observed with a broken leg for ~3 weeks prior to mortality ## 3 2.4.5 Resight Table This table contains data on individual resights of collared sheep and lambs, collected during observations. A resightID will serve as the primary key.The sheepID of the collared ewe will be recorded as well as her lamb status (whether she has a lamb at heel) along with the name of that lamb. Date and which group observation this resight was a part of (groupID) will also be recorded. SheepID, name, and groupID will serve as foreign keys linking back up to the Sheep, Lambs, and Observations Tables, respectivley. dbExecute(jd_sheep_db, &quot;CREATE TABLE resight ( resight_id varchar(30) NOT NULL PRIMARY KEY, name varchar (15), sheep_id varchar(15), status varchar(7) CHECK (status IN (&#39;nursing&#39;, &#39;follow&#39;, &#39;contact&#39;, &#39;bedded&#39;, &#39;unknown&#39;, &#39;none&#39;)), date date, group_id char(7), FOREIGN KEY (name) REFERENCES lambs(name) FOREIGN KEY (sheep_id) REFERENCES sheep(sheep_id), FOREIGN KEY (group_id) REFERENCES observations(group_id) );&quot;) Read in the csv file. resight &lt;- read.csv(&quot;../../../Project/Data/raw/Database/resight.csv&quot;) Double check csv matches empty table. names(resight) ## [1] &quot;resight_id&quot; &quot;sheep_id&quot; &quot;name&quot; &quot;status&quot; &quot;date&quot; ## [6] &quot;group_id&quot; head(resight, 3) ## resight_id sheep_id name status date group_id ## 1 240517Ao60 orange60 baker nursing 5/17/2024 240517A ## 2 240517Ap11 purple11 sister nursing 5/17/2024 240517A ## 3 240517Aw35 white35 hood nursing 5/17/2024 240517A Populate the table. dbWriteTable(jd_sheep_db, &quot;resight&quot;, resight, append = TRUE) Confirm that the data was loaded properly. dbGetQuery(jd_sheep_db, &quot;SELECT * FROM resight LIMIT 3&quot;) ## resight_id name sheep_id status date group_id ## 1 240517Ao60 baker orange60 nursing 5/17/2024 240517A ## 2 240517Ap11 sister purple11 nursing 5/17/2024 240517A ## 3 240517Aw35 hood white35 nursing 5/17/2024 240517A 2.4.6 Group Behavior Table Group behavior will be recorded multiple times during observations and will include the proportion of animals in the group who are foraging, vigilant, traveling, or bedded. A timestamp of each behavior snapshot will serve as the primary key, and will link back up with the Observations Table using groupID as the foreign key. dbExecute(jd_sheep_db, &quot;CREATE TABLE group_behavior ( timestamp datetime NOT NULL PRIMARY KEY, foraging integer, vigilant integer, traveling integer, bedded integer, sun_shade varchar(5), group_id char(7), notes varchar, FOREIGN KEY (group_id) REFERENCES observations(group_id) );&quot;) Read in the csv file. group_behavior &lt;- read.csv(&quot;../../../Project/Data/raw/Database/group_behavior.csv&quot;) Double check csv matches empty table. names(group_behavior) ## [1] &quot;timestamp&quot; &quot;bedded&quot; &quot;foraging&quot; &quot;vigilant&quot; &quot;traveling&quot; &quot;sun_shade&quot; ## [7] &quot;group_id&quot; &quot;notes&quot; head(group_behavior, 3) ## timestamp bedded foraging vigilant traveling sun_shade group_id notes ## 1 5/17/2024 9:40 6 19 8 1 sun 240517A ## 2 5/17/2024 10:48 19 0 4 0 sun 240517B ## 3 5/20/2024 8:38 2 1 0 0 sun 240520A Populate the table. dbWriteTable(jd_sheep_db, &quot;group_behavior&quot;, group_behavior, append = TRUE) Confirm that the data was loaded properly. dbGetQuery(jd_sheep_db, &quot;SELECT * FROM group_behavior LIMIT 3&quot;) ## timestamp foraging vigilant traveling bedded sun_shade group_id notes ## 1 5/17/2024 9:40 19 8 1 6 sun 240517A ## 2 5/17/2024 10:48 0 4 0 19 sun 240517B ## 3 5/20/2024 8:38 1 0 0 2 sun 240520A 2.4.7 Collars Table The collars table contains information about the GPS collars including serial numbers, frequencies, visual marker inforation (tag number and color), which side the hardware is on, whether it is deployed, on mortality, or retreived, the date it was deployed and the date it was retrieved. Which sheep (sheepID) the collar is affixed to will serve as a foreign key linking back to the Sheep Table. A collarID will serve as the primary key. dbExecute(jd_sheep_db, &quot;CREATE TABLE collars ( collar_id char(8) NOT NULL PRIMARY KEY, sheep_id varchar(15), serial varchar(5), frequency real, tag_number integer, tag_color varchar(10), hardware varchar(5) CHECK (hardware IN (&#39;Right&#39;, &#39;Left&#39;)), status varchar(9) CHECK (status IN (&#39;deployed&#39;, &#39;data&#39;, &#39;clean&#39;)), deployed date, retrieved date, FOREIGN KEY (sheep_id) REFERENCES sheep(sheep_id) );&quot;) Read in the csv file. collars &lt;- read.csv(&quot;../../../Project/Data/raw/Database/collars.csv&quot;) Double check csv matches empty table. names(group_behavior) ## [1] &quot;timestamp&quot; &quot;bedded&quot; &quot;foraging&quot; &quot;vigilant&quot; &quot;traveling&quot; &quot;sun_shade&quot; ## [7] &quot;group_id&quot; &quot;notes&quot; head(group_behavior, 3) ## timestamp bedded foraging vigilant traveling sun_shade group_id notes ## 1 5/17/2024 9:40 6 19 8 1 sun 240517A ## 2 5/17/2024 10:48 19 0 4 0 sun 240517B ## 3 5/20/2024 8:38 2 1 0 0 sun 240520A Populate the table. dbWriteTable(jd_sheep_db, &quot;collars&quot;, collars, append = TRUE) Confirm that the data was loaded properly. dbGetQuery(jd_sheep_db, &quot;SELECT * FROM collars LIMIT 3&quot;) ## collar_id sheep_id serial frequency tag_number tag_color hardware status ## 1 24_97197 Purple7 97197 151.48 7 Purple Left deployed ## 2 24_97198 Yellow91 97198 151.63 91 Yellow Right deployed ## 3 24_97199 Orange60 97199 151.38 60 Orange Left deployed ## deployed retrieved ## 1 2/16/2024 ## 2 2/16/2024 ## 3 2/16/2024 2.4.8 Spatial Data Table The spatial data table contains locations transmitted from GPS collars. A gpsID will serve as the primary key. Which sheep (sheepID) and collar (collarID) the location came from will serve as foreign keys linking back up to the Sheep and Collar Tables, respectively. dbExecute(jd_sheep_db, &quot;CREATE TABLE spatial_data ( point_id varchar NOT NULL PRIMARY KEY, sheep_id varchar(15), collar_id char(8), timestamp datetime, lat real, long real );&quot;) I do not yet have my spatial data and therefore will not populate the table at this time, but use the code below to do so when I’m ready. #load csv spatial_data &lt;- read.csv(&quot;../../../Project/Data/raw/Database/spatial_data.csv&quot;) #double check csv matches empty table names(spatial_data) head(spatial_data, 3) #populate the table dbWriteTable(jd_sheep_db, &quot;spatial_data&quot;, spatial_data, append = TRUE) #confirm data was loaded properly dbGetQuery(jd_sheep_db, &quot;SELECT * FROM spatial_data LIMIT 3&quot;) "],["data-cleaning.html", "Chapter 3 Data Cleaning 3.1 Tidy Data 3.2 The Tidyverse", " Chapter 3 Data Cleaning 3.1 Tidy Data Clean and organized data are necessary for efficient and successful analyses. The concept of tidy data serves as a guiding principle for achieving this organization. Fundamentally, tidy data adhere to three simple yet powerful rules: each variable is represented by a column, each observation is represented by a row, and each cell contains a single measurement. Variables are the aspects being measured, such as biomass of forage or group size, while observations are repeated measurements of those variables across different experimental units. Because I created my relational database before entering any data, I did not need to clean my data prior to populating my database. However, below contains information of how to use tidyverse to effectively manipulate data for future reference. 3.2 The Tidyverse The tidyverse is a collection of R packages designed for data science, offering tools that make data manipulation, visualization, and analysis more intuitive and efficient. By installing and loading the tidyverse package, it will automattically attach the 9 packages that are part of the tidyverse. library(tidyverse) ## ── Attaching core tidyverse packages ## ✔ dplyr 1.1.3 ✔ readr 2.1.5 ## ✔ forcats 1.0.0 ✔ stringr 1.5.0 ## ✔ ggplot2 3.4.3 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.3 ✔ tidyr 1.3.0 ## ✔ purrr 1.0.2 ## ── Conflicts ─────────────────────── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors dplyr is especially useful for data cleaning and manipulation. Some of the most commonly used functions include mutate(), filter(), case_when(), select(), and arrange(). Below, are examples of how to use these functions. 3.2.1 Mutate Use mutate() to add a new column or modify an existing one. For example, calculate whether the sheep is “Yearling” or “Adult” based on age. mutate(age = ifelse(Age &lt; 2, &quot;yearling&quot;, &quot;adult&quot;)) 3.2.2 Filter Use filter() to extract rows that meet a specific condition. For instance, extract only female sheep. ewes &lt;- sheep %&gt;% filter(Sex == &quot;F&quot;) 3.2.3 Case_when() Use case_when() to assign values based on multiple conditions. For example, create a new column by classifying total sheep in group to a group size of “Small,” “Medium,” or “Large”. observations &lt;- observations %&gt;% mutate(group_size = case_when( total &lt; 10 ~ &quot;Small&quot;, total &gt; 35 ~ &quot;Large&quot;, TRUE ~ &quot;Medium&quot; )) 3.2.4 Select Use select() to keep only the columns you need. For example, extract columns related to biological samples: fecal, blood, dna, and nasal. sample_checklist &lt;- sheep %&gt;% select(fecal, blood, dna, nasal) 3.2.5 Arrange Use arrange() to sort rows. For instance, order the dataset by number of ewes in a group in descending order: observations &lt;- observations %&gt;% arrange(desc(ewes)) "],["data-exploration.html", "Chapter 4 Data Exploration 4.1 Summary Statistics 4.2 Data Vizualizations 4.3 Exploring Data", " Chapter 4 Data Exploration Data exploration is a crucial step in any research process, providing insights into the relationships, patterns, and potential anomalies within a dataset. Before conducting formal analyses, exploring data helps to identify trends, assess distributions, and ensure the quality and consistency of the data. By exploring the data visually, you can build an intuitive understanding of the dataset, ultimately leading to more robust and informed analyses. Below are several examples of how one can explore their data. *Imporant note: I have not entered all of my data and am only using a subset. Results from the code in this chapter may not represent the dataset accurately. Before exploring the data, ensure the database and applicable packages are loaded correctly #load packages library(DBI) library(tidyverse) #load database jd_sheep_db &lt;- dbConnect(RSQLite::SQLite(), &quot;../../../Project/Data/raw/Database/jd_sheep.db&quot;) #load tables sheep &lt;- dbGetQuery(jd_sheep_db, &quot;SELECT * FROM sheep;&quot;) observations &lt;- dbGetQuery(jd_sheep_db, &quot;SELECT * FROM observations;&quot;) mortalities &lt;- dbGetQuery(jd_sheep_db, &quot;SELECT * FROM mortalities;&quot;) lambs &lt;- dbGetQuery(jd_sheep_db, &quot;SELECT * FROM lambs;&quot;) resight &lt;- dbGetQuery(jd_sheep_db, &quot;SELECT * FROM resight;&quot;) group_behavior &lt;- dbGetQuery(jd_sheep_db, &quot;SELECT * FROM group_behavior;&quot;) collars &lt;- dbGetQuery(jd_sheep_db, &quot;SELECT * FROM collars;&quot;) spatial_data &lt;- dbGetQuery(jd_sheep_db, &quot;SELECT * FROM spatial_data;&quot;) 4.1 Summary Statistics A good first step in exploring data often involves calculating summary statistics. These provide a concise numerical overview of key aspects of the data, such as measures of central tendency (e.g., mean, median) and variability (e.g., standard deviation, range). Summary statistics are particularly useful for comparing groups or understanding distributions within the dataset, serving as a foundation for further exploration and analysis. #create a table that summarizes the minimum, maximum, and mean of sheep observed in a group, calculated as a group total as well as for each age-sex class group_summary &lt;- observations %&gt;% select(total, ewes, lambs, year_ewes, year_rams, rams) %&gt;% summarise(across(everything(), list(mean = function(x) mean(x), min = function(x) min(x), max = function(x) max(x)), .names = &quot;{col}_{fn}&quot; ) ) group_summary ## total_mean total_min total_max ewes_mean ewes_min ewes_max lambs_mean ## 1 22.91667 2 60 14.125 1 34 7.375 ## lambs_min lambs_max year_ewes_mean year_ewes_min year_ewes_max year_rams_mean ## 1 0 26 1.166667 0 6 0.2083333 ## year_rams_min year_rams_max rams_mean rams_min rams_max ## 1 0 1 0.04166667 0 1 4.2 Data Vizualizations In R, ggplot is one of the most powerful and flexible packages for creating high-quality plots. Based on the Grammar of Graphics, ggplot allows users to build plots layer by layer, providing full control over the appearance and components of the visualizations. ggplot is great both for creating rudimentary plots used to explore your data, as well as detailed and beautiful plots demonstrating results from analyses. 4.2.1 Simple Plots Here’s a simple example that demonstrates to build-on structure of ggplot using geoom_point to create a scatter plot of ewes vs lambs in groups. ggplot(data = observations, #table containing desired variables mapping = aes(x = lambs, #defining axis y = ewes)) + geom_point(col = &quot;darkmagenta&quot;) + #plot type, add color labs(x = &quot;Number of Lambs&quot;, #adding labels y = &quot;Number of Ewes&quot;) + theme_light() #choosing theme of plot Here is another example, but this time creating a histogram of maximum body temperature of sheep during capture using geom_historgram. Overheating is a common issue for bighorn sheep during capture, and as such, there are several mitigation tactics we have on hand to reduce heat stress to the animals. For reference, mitigation efforts usually begin if the animal reaches 106 F and will increase in rigor if the sheep’s temperature continues to climb. ggplot(data = sheep, mapping = aes(x = temp)) + geom_histogram() + labs(x = &quot;Maximum Body Temperature (F)&quot;) ## `stat_bin()` using `bins = 30`. ## Pick better value with `binwidth`. 4.3 Exploring Data 4.3.1 Relationship Between Group Size and Behavior Through this research, I hope to uncover the relationship between survival and group size. I hypothesize that as group size increases survival of both lambs and adult ewes will also increase. A biological mechanism that could explain this relationship is the level of vigilance a group provides. I am curious about the relationship between total group size and the number of animals in each group performing vigilant behavior. # Join the observations and group_behavior tables, then plot the relationship observations %&gt;% left_join(group_behavior, by = &quot;group_id&quot;) %&gt;% ggplot(mapping = aes(x = total, y = vigilant)) + geom_point(color = &quot;navyblue&quot;, size = 2) + labs(x = &quot;Group Size&quot;, y = &quot;Count of Vigilant Animals&quot;, title = &quot;Group Size vs. Vigilance&quot;) + theme_minimal() There doesn’t seem to be a strong relationship here. One of the benefits of a larger group is that individuals can relax their vigilance, while still benefiting from the heightened awareness of others, this is known as the “many eyes hypothesis.” I’m curious about the relationship between group size and foraging behavior. But I might as well plot the proportion of animals performing each behavior in the group to get a full picture of how behavior is distributed among individuals in a group. #to do this, I will need to resahpe the data into long format to get a count for each behavior before plotting observations %&gt;% left_join(group_behavior, by = &quot;group_id&quot;) %&gt;% #join the tables pivot_longer(cols = c(foraging, vigilant, traveling, bedded), names_to = &quot;behavior&quot;, values_to = &quot;count&quot;) %&gt;% ggplot(mapping = aes(x = total, y = count, color = behavior)) + geom_point(size = 2) + labs(title = &quot;Group Size vs. Behavioral Counts&quot;, x = &quot;Group Size&quot;, y = &quot;Count of Behavior&quot;, color = &quot;Behavior&quot;) + theme_minimal() I find it interesting that vigilance seems to stay somewhat constant, despite the change in group size. I wonder if there is some type of threshold effect of “maximum vigilance required” to reduce risk and after that threshold is reached, vigilant behavior is no longer worth the sacrifice of energy that could be spent on another behavior. That would be a really cool relationship to observe! 4.3.2 Survival Another key objective of this research is to determine survival rates of both lambs and adult ewes. I want to explore the counts of total ewes and lambs alive vs. dead. Because this data is stored in multiple tables and not necessarily in the format need to count, it will require a bit of manipulation before I can plot these data. sheep %&gt;% left_join(lambs, by = &quot;sheep_id&quot;) %&gt;% #join lamb data with individual sheep data left_join(mortalities, by = &quot;sheep_id&quot;) %&gt;% #join with mortalities table filter(sex == &quot;F&quot;) %&gt;% #keep only ewes mutate(lamb_status = case_when( fate == &quot;weaned&quot; ~ &quot;Alive&quot;, #weaned lambs are alive fate == &quot;deceased&quot; ~ &quot;Dead&quot;, #deceased lambs are dead fate == &quot;unknwn&quot; ~ &quot;Unknown&quot;, #lambs with unknown fate )) %&gt;% mutate(ewe_status = case_when( is.na(cause) ~ &quot;Alive&quot;, #ewes without cause of death are alive !is.na(cause) ~ &quot;Dead&quot; #ewes with a cause of death are dead ) ) %&gt;% select(lamb_status, ewe_status) %&gt;% pivot_longer(cols = c(lamb_status, ewe_status), #pivot to count alive vs. dead names_to = &quot;status_type&quot;, values_to = &quot;status&quot;) %&gt;% filter(!is.na(status)) %&gt;% #remove NAs mutate(status_type = case_when( status_type == &quot;lamb_status&quot; ~ &quot;Lambs&quot;, #change the names to make plot prettier status_type == &quot;ewe_status&quot; ~ &quot;Ewes&quot; )) %&gt;% count(status_type, status) %&gt;% ggplot(mapping = aes(x = status, y = n, fill = status)) + geom_bar(stat = &quot;identity&quot;) + facet_wrap(~status_type, scales = &quot;free_y&quot;) + #facet for panels scale_fill_viridis_d() + #viridis color scheme labs( title = &quot;Ewe and Lamb Survival&quot;, x = NULL, #remove x-axis y = &quot;Count&quot; ) + theme_minimal() + theme( axis.text.x = element_blank(), #remove redudant labels strip.text = element_text(size = 12, face = &quot;bold&quot;) ) Mortality was higher for adult ewes than I would have expected. Lamb mortality is about what I would expect for a growing sheep population. "],["conclusion.html", "Chapter 5 Conclusion 5.1 References", " Chapter 5 Conclusion This document provides a record of data preparation steps for my research on the Lower John Day bighorn sheep population. By documenting the process of creating, cleaning, and exploring the dataset, I aimed to ensure transparency and reproducibility. I hope this document will serve as a helpful reference for verifying data manipulations and as a guide, both for my future self as well as others working on similar projects. 5.1 References https://ecorepsci.github.io/reproducible-science/index.html "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
